{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/training/train-in-spark/train-in-spark.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05. Train in Spark\n",
        "* Create Workspace\n",
        "* Create Experiment\n",
        "* Copy relevant files to the script folder\n",
        "* Configure and Run"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration](../../../configuration.ipynb) Notebook first if you haven't already to establish your connection to the AzureML Workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.22.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1613700198280
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Workspace\n",
        "\n",
        "Initialize a workspace object from persisted configuration."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zhenzhuuksouth\n",
            "zhenzhuuksouth\n",
            "uksouth\n",
            "e9b2ec51-5c94-4fa8-809a-dc1e695e4896\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1613700206293
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Experiment\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'train-on-spark-on-CI'\n",
        "\n",
        "from azureml.core import Experiment\n",
        "exp = Experiment(workspace=ws, name=experiment_name)\n",
        "run = exp.start_logging()"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1613701641122
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View `train-spark.py`\n",
        "\n",
        "For convenience, we created a training script for you. It is printed below as a text, but you can also run `%pfile ./train-spark.py` in a cell to show the file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Microsoft. All rights reserved.\n",
        "# Licensed under the MIT license.\n",
        "\n",
        "import numpy as np\n",
        "import pyspark\n",
        "import os\n",
        "import urllib\n",
        "import sys\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.classification import *\n",
        "from pyspark.ml.evaluation import *\n",
        "from pyspark.ml.feature import *\n",
        "from pyspark.sql.types import StructType, StructField\n",
        "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
        "\n",
        "from azureml.core.run import Run\n",
        "\n",
        "# initialize logger\n",
        "\n",
        "\n",
        "# start Spark session\n",
        "spark = pyspark.sql.SparkSession.builder.appName('Iris').getOrCreate()\n",
        "\n",
        "# print runtime versions\n",
        "print('****************')\n",
        "print('Python version: {}'.format(sys.version))\n",
        "print('Spark version: {}'.format(spark.version))\n",
        "print('****************')\n",
        "\n",
        "# load iris.csv into Spark dataframe\n",
        "schema = StructType([\n",
        "    StructField(\"sepal-length\", DoubleType()),\n",
        "    StructField(\"sepal-width\", DoubleType()),\n",
        "    StructField(\"petal-length\", DoubleType()),\n",
        "    StructField(\"petal-width\", DoubleType()),\n",
        "    StructField(\"class\", StringType())\n",
        "])\n",
        "\n",
        "data = spark.read.format(\"com.databricks.spark.csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(schema) \\\n",
        "    .load(\"iris.csv\")\n",
        "\n",
        "print(\"First 10 rows of Iris dataset:\")\n",
        "data.show(10)\n",
        "\n",
        "# vectorize all numerical columns into a single feature column\n",
        "feature_cols = data.columns[:-1]\n",
        "assembler = pyspark.ml.feature.VectorAssembler(\n",
        "    inputCols=feature_cols, outputCol='features')\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# convert text labels into indices\n",
        "data = data.select(['features', 'class'])\n",
        "label_indexer = pyspark.ml.feature.StringIndexer(\n",
        "    inputCol='class', outputCol='label').fit(data)\n",
        "data = label_indexer.transform(data)\n",
        "\n",
        "# only select the features and label column\n",
        "data = data.select(['features', 'label'])\n",
        "print(\"Reading for machine learning\")\n",
        "data.show(10)\n",
        "\n",
        "# change regularization rate and you will likely get a different accuracy.\n",
        "reg = 0.01\n",
        "# load regularization rate from argument if present\n",
        "# if len(sys.argv) > 1:\n",
        "#     reg = float(sys.argv[1])\n",
        "\n",
        "# log regularization rate\n",
        "run.log(\"Regularization Rate\", reg)\n",
        "\n",
        "# use Logistic Regression to train on the training set\n",
        "train, test = data.randomSplit([0.70, 0.30])\n",
        "lr = pyspark.ml.classification.LogisticRegression(regParam=reg)\n",
        "model = lr.fit(train)\n",
        "\n",
        "model.save(os.path.join(\"outputs\", \"iris.model\"))\n",
        "\n",
        "# predict on the test set\n",
        "prediction = model.transform(test)\n",
        "print(\"Prediction\")\n",
        "prediction.show(10)\n",
        "\n",
        "# evaluate the accuracy of the model using the test set\n",
        "evaluator = pyspark.ml.evaluation.MulticlassClassificationEvaluator(\n",
        "    metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(prediction)\n",
        "\n",
        "print()\n",
        "print('#####################################')\n",
        "print('Regularization rate is {}'.format(reg))\n",
        "print(\"Accuracy is {}\".format(accuracy))\n",
        "print('#####################################')\n",
        "print()\n",
        "\n",
        "# log accuracy\n",
        "run.log('Accuracy', accuracy)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************\n",
            "Python version: 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n",
            "[GCC 7.3.0]\n",
            "Spark version: 3.0.0\n",
            "****************\n",
            "First 10 rows of Iris dataset:\n",
            "+------------+-----------+------------+-----------+-----------+\n",
            "|sepal-length|sepal-width|petal-length|petal-width|      class|\n",
            "+------------+-----------+------------+-----------+-----------+\n",
            "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
            "|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n",
            "|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n",
            "|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n",
            "|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n",
            "|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n",
            "|         5.4|        3.7|         1.5|        0.2|Iris-setosa|\n",
            "+------------+-----------+------------+-----------+-----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Reading for machine learning\n",
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[4.9,3.0,1.4,0.2]|  2.0|\n",
            "|[4.7,3.2,1.3,0.2]|  2.0|\n",
            "|[4.6,3.1,1.5,0.2]|  2.0|\n",
            "|[5.0,3.6,1.4,0.2]|  2.0|\n",
            "|[5.4,3.9,1.7,0.4]|  2.0|\n",
            "|[4.6,3.4,1.4,0.3]|  2.0|\n",
            "|[5.0,3.4,1.5,0.2]|  2.0|\n",
            "|[4.4,2.9,1.4,0.2]|  2.0|\n",
            "|[4.9,3.1,1.5,0.1]|  2.0|\n",
            "|[5.4,3.7,1.5,0.2]|  2.0|\n",
            "+-----------------+-----+\n",
            "only showing top 10 rows\n",
            "\n",
            "Prediction\n",
            "+-----------------+-----+--------------------+--------------------+----------+\n",
            "|         features|label|       rawPrediction|         probability|prediction|\n",
            "+-----------------+-----+--------------------+--------------------+----------+\n",
            "|[4.4,3.2,1.3,0.2]|  2.0|[1.88489576659543...|[0.01529559573860...|       2.0|\n",
            "|[4.5,2.3,1.3,0.3]|  2.0|[2.71074616396220...|[0.34834639801272...|       2.0|\n",
            "|[4.8,3.0,1.4,0.3]|  2.0|[2.21324489827196...|[0.07242114089298...|       2.0|\n",
            "|[4.9,2.4,3.3,1.0]|  0.0|[1.91227844865584...|[0.85202350655110...|       0.0|\n",
            "|[4.9,2.5,4.5,1.7]|  1.0|[1.03858025891153...|[0.48479198243671...|       1.0|\n",
            "|[5.0,3.4,1.6,0.4]|  2.0|[1.84033080320984...|[0.03269687661664...|       2.0|\n",
            "|[5.1,3.8,1.5,0.3]|  2.0|[1.62208423942492...|[0.00788728649574...|       2.0|\n",
            "|[5.1,3.8,1.9,0.4]|  2.0|[1.46416252307636...|[0.01155262447210...|       2.0|\n",
            "|[5.2,2.7,3.9,1.4]|  0.0|[1.38144947747208...|[0.79759330531394...|       0.0|\n",
            "|[5.2,3.4,1.4,0.2]|  2.0|[2.15311282089439...|[0.03240312052690...|       2.0|\n",
            "+-----------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "#####################################\n",
            "Regularization rate is 0.01\n",
            "Accuracy is 1.0\n",
            "#####################################\n",
            "\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1613701737239
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monitor the run using a Juypter widget"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb2d9198cdf2484d8ba388cbd40fdd57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/train-on-spark-mmlspark/runs/83bd1152-1cb2-4769-9a0a-c5a2fee33e92?wsid=/subscriptions/e9b2ec51-5c94-4fa8-809a-dc1e695e4896/resourcegroups/zhenzhuuksouth/workspaces/zhenzhuuksouth\", \"run_id\": \"83bd1152-1cb2-4769-9a0a-c5a2fee33e92\", \"run_properties\": {\"run_id\": \"83bd1152-1cb2-4769-9a0a-c5a2fee33e92\", \"created_utc\": \"2021-02-19T02:27:17.079375Z\", \"properties\": {\"azureml.git.repository_uri\": \"https://github.com/AbeOmor/Spark-in-AzureML.git\", \"mlflow.source.git.repoURL\": \"https://github.com/AbeOmor/Spark-in-AzureML.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"6893881dcdb4439af7688d26ee7b0b097634ade5\", \"mlflow.source.git.commit\": \"6893881dcdb4439af7688d26ee7b0b097634ade5\", \"azureml.git.dirty\": \"True\", \"ContentSnapshotId\": \"f08d915e-d765-4640-b5b3-4136b64236ae\"}, \"tags\": {}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:04:08\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"83bd1152-1cb2-4769-9a0a-c5a2fee33e92\", \"categories\": [0, 1], \"series\": [{\"data\": [0.01, 0.01]}]}, {\"name\": \"Accuracy\", \"run_id\": \"83bd1152-1cb2-4769-9a0a-c5a2fee33e92\", \"categories\": [0], \"series\": [{\"data\": [1.0]}]}], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.22.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613701840499
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: if you need to cancel a run, you can follow [these instructions](https://aka.ms/aml-docs-cancel-run).\r\n",
        "\r\n",
        "After the run is succesfully finished, you can check the metrics logged."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all metris logged in the run\r\n",
        "metrics = run.get_metrics()\r\n",
        "print(metrics)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Regularization Rate': [0.01, 0.01], 'Accuracy': 1.0}\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613701847172
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# register the generated model\r\n",
        "model = run.register_model(model_name='iris.model', model_path='outputs/iris.model')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "index_order": 1,
    "exclude_from_index": false,
    "task": "Submiting a run on a spark cluster",
    "deployment": [
      "None"
    ],
    "authors": [
      {
        "name": "sanpil"
      }
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "compute": [
      "HDI cluster"
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "tags": [
      "None"
    ],
    "datasets": [
      "None"
    ],
    "categories": [
      "how-to-use-azureml",
      "training"
    ],
    "category": "training",
    "framework": [
      "PySpark"
    ],
    "friendly_name": "Training in Spark",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}